{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics supervision==0.20.0 opencv-python deep-sort-realtime -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCFalmdB4O5Z",
        "outputId": "977d0813-fcaf-4b94-c304-cc7bc82f9801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/111.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”\u001b[0m \u001b[32m7.8/8.4 MB\u001b[0m \u001b[31m235.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2vnxUkWhc9",
        "outputId": "343eeb61-104c-4dab-d420-f1ac89c5d344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 110.0MB/s 0.1s\n",
            "âœ… Processing complete. Output saved as output.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# ğŸ”¹ Set your video path here\n",
        "video_path = \"/content/lost.mp4\"   # <<--- change this to your video file path\n",
        "\n",
        "# Load YOLO model + DeepSORT\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "tracker = DeepSort(max_age=30)\n",
        "\n",
        "# Trackers\n",
        "bag_owner = {}\n",
        "unattended_timer = {}\n",
        "theft_alert = set()\n",
        "\n",
        "def is_near(box1, box2, threshold=100):\n",
        "    \"\"\"Check if two boxes are near each other\"\"\"\n",
        "    x1, y1, x2, y2 = box1\n",
        "    cx1, cy1 = (x1+x2)//2, (y1+y2)//2\n",
        "    x3, y3, x4, y4 = box2\n",
        "    cx2, cy2 = (x3+x4)//2, (y3+y4)//2\n",
        "    dist = ((cx1-cx2)**2 + (cy1-cy2)**2) ** 0.5\n",
        "    return dist < threshold\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"output.mp4\", fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
        "                      (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "frame_count = 0\n",
        "UNATTENDED_THRESHOLD = int(cap.get(cv2.CAP_PROP_FPS) * 5)  # 5 sec\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_count += 1\n",
        "\n",
        "    # Run YOLO\n",
        "    results = model(frame, verbose=False)[0]\n",
        "    detections = []\n",
        "\n",
        "    for box in results.boxes:\n",
        "        cls = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        if conf < 0.5:\n",
        "            continue\n",
        "        # Detect people + bags (backpack=24, handbag=25, suitcase=26)\n",
        "        if cls in [0, 24, 25, 26]:\n",
        "            detections.append([[x1, y1, x2-x1, y2-y1], conf, cls])\n",
        "\n",
        "    # Update DeepSORT tracker\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "    people, bags = {}, {}\n",
        "\n",
        "    for t in tracks:\n",
        "        if not t.is_confirmed():\n",
        "            continue\n",
        "        l, t_, r, b = map(int, t.to_ltrb())\n",
        "        track_id = t.track_id\n",
        "        cls = t.get_det_class()\n",
        "\n",
        "        if cls == 0:\n",
        "            people[track_id] = (l, t_, r, b)\n",
        "            cv2.rectangle(frame, (l, t_), (r, b), (255, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Person {track_id}\", (l, t_-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
        "        elif cls in [24, 25, 26]:\n",
        "            bags[track_id] = (l, t_, r, b)\n",
        "\n",
        "    # Handle bag logic\n",
        "    for bag_id, bag_box in bags.items():\n",
        "        owner_id = None\n",
        "        for pid, pbox in people.items():\n",
        "            if is_near(bag_box, pbox, threshold=120):\n",
        "                owner_id = pid\n",
        "                break\n",
        "\n",
        "        if owner_id is None:\n",
        "            # Bag is unattended\n",
        "            if bag_id not in unattended_timer:\n",
        "                unattended_timer[bag_id] = frame_count\n",
        "            if frame_count - unattended_timer[bag_id] > UNATTENDED_THRESHOLD:\n",
        "                cv2.putText(frame, \"âš  Unattended Bag!\", (bag_box[0], bag_box[1]-10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
        "                cv2.rectangle(frame, (bag_box[0], bag_box[1]),\n",
        "                              (bag_box[2], bag_box[3]), (0,0,255), 3)\n",
        "        else:\n",
        "            # Bag with an owner\n",
        "            unattended_timer.pop(bag_id, None)\n",
        "            if bag_id in bag_owner and bag_owner[bag_id] != owner_id:\n",
        "                theft_alert.add(bag_id)\n",
        "            bag_owner[bag_id] = owner_id\n",
        "\n",
        "        # Theft detection persistent alert\n",
        "        if bag_id in theft_alert:\n",
        "            cv2.putText(frame, \"ğŸš¨ Theft Detected!\", (bag_box[0], bag_box[1]-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
        "            cv2.rectangle(frame, (bag_box[0], bag_box[1]),\n",
        "                          (bag_box[2], bag_box[3]), (0,0,255), 3)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"âœ… Processing complete. Output saved as output.mp4\")\n"
      ]
    }
  ]
}